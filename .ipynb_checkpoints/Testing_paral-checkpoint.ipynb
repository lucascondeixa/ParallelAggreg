{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics, OrderedCollections, Dates, Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"aggreg.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using EnergySystemModeling: SeriesInstance,\n",
    "#     ClustInstance,\n",
    "#     AggregInstance,\n",
    "#     DistUpdate,\n",
    "#     load_series_instance,\n",
    "#     load_clust_instance,\n",
    "#     aggreg1D,\n",
    "#     cdad,\n",
    "#     search_min_dist,\n",
    "#     compute_dist,\n",
    "#     update_marker,\n",
    "#     replace_lines,\n",
    "#     update_clust!,\n",
    "#     update_k!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new copy method to copy _ClustInstance and _SeriesInstance\n",
    "Base.copy(x::T) where T = T([getfield(x, k) for k âˆˆ fieldnames(T)]...);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_serial (generic function with 1 method)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_serial(series::VecOrMat{Float64},\n",
    "    block_size::Int,\n",
    "    stopping_k::Int,\n",
    "    current_k::Int,\n",
    "    dm::Symbol,\n",
    "    rep_value::Symbol,\n",
    "    lseries::Int,\n",
    "    nseries::Int,\n",
    "    series_dc::VecOrMat{Float64},\n",
    "    ord_dc::VecOrMat{Int},\n",
    "    k_cent::VecOrMat{Float64},\n",
    "    weights::Vector{Int},\n",
    "    series_clust::Vector{Int},\n",
    "    nclusters::Int,\n",
    "    search_range::UnitRange,\n",
    "    dc_mode::Bool,\n",
    "    _SeriesInstance::SeriesInstance,\n",
    "    _ClustInstance::ClustInstance,\n",
    "    _DistUpdate::Dict{Vector{Bool},DistUpdate},\n",
    "    _SeriesUpdate::Dict{String,SeriesInstance},\n",
    "    _ClustUpdate::Dict{String,ClustInstance})\n",
    "\n",
    "    # @info \"Clustering the next step\"\n",
    "    k = lseries\n",
    "    @time while k >= stopping_k + block_size - 1\n",
    "        \n",
    "        # Vector with distances (to be updated as it goes)\n",
    "        dist = Vector{Float64}(undef,length(search_range))\n",
    "\n",
    "        # Sets\n",
    "        N = 1:nseries\n",
    "        K = copy(search_range)\n",
    "\n",
    "        # Compute the distance for each aggregation (i.e., changing the merging_clust)\n",
    "        # TODO: implement parallelisation such as '@async Threads.@threads @inbounds for k in K'\n",
    "        @inbounds for k_search in K\n",
    "            # Merging to be tested (neighbouring hypothesis)\n",
    "            # TODO: implement non-neighbouring hypothesis\n",
    "            merging_clust = k_search:k_search+block_size-1\n",
    "            # Create a temporary marker to merge the clusters tested\n",
    "            marker_temp = [sc in merging_clust for sc in series_clust]\n",
    "\n",
    "            # Separation needed for duration curves analysis\n",
    "            if dc_mode\n",
    "                # Create a temp marker for the elements in between clustered [min,max] order\n",
    "                marker_temp_dc = minimum(ord_dc[marker_temp,:]):maximum(ord_dc[marker_temp,:])\n",
    "                # Using duration curves chunks (in between the min and max values of marker_temp)\n",
    "                series_comp = sort(series, dims=1,rev=true)[marker_temp_dc,:]\n",
    "                # Forming the centroids\n",
    "                k_cent_comp = copy(series)\n",
    "                (k_cent_comp[marker_temp,:],) = aggreg1D(series[marker_temp,:], rep_value)\n",
    "                # Ordering chunk with clustering instance in a decrescent order\n",
    "                k_cent_comp = sort(k_cent_comp, dims=1, rev=true)[marker_temp_dc,:]\n",
    "            else\n",
    "                # Part of series compared\n",
    "                series_comp = series[marker_temp,:]\n",
    "                # Centroids of the temporarily formed cluster (TODO: implement another method for aggreg1D receiving the clusters with respective weights)\n",
    "                (k_cent_comp,) = aggreg1D(series_comp, rep_value)\n",
    "            end\n",
    "            \n",
    "            # Distance computation\n",
    "            dist[k_search] = compute_dist(N, dm, series_comp, k_cent_comp)\n",
    "        end\n",
    "\n",
    "        # Find whenever the min_dist occurs first (i.e., using findmin()[2])\n",
    "        ## TODO: implement the multiple merges (e.g., using findall())\n",
    "        min_dist = findmin(dist)[2] |> Int        \n",
    "        merging_clust = min_dist:min_dist+block_size-1\n",
    "\n",
    "        # Create a flag to the positions in the series that will be aggregated\n",
    "        marker = update_marker(_SeriesInstance, _ClustInstance, min_dist)    \n",
    "\n",
    "        # Update _DistUpdate dictionary with the minimal distance found and the new marker\n",
    "        _DistUpdate = merge(+, _DistUpdate, Dict(marker => DistUpdate(min_dist,merging_clust)))\n",
    "\n",
    "        # Update clusters and series_clust\n",
    "        update_clust!(_ClustInstance, _SeriesInstance, min_dist)\n",
    "\n",
    "        # Update clustering values\n",
    "        series_clust = _ClustInstance.series_clust\n",
    "        weights = _ClustInstance.weights\n",
    "\n",
    "        nclusters = _ClustInstance.nclusters\n",
    "        k_cent = _ClustInstance.k_cent\n",
    "        search_range =_ClustInstance.search_range\n",
    "        \n",
    "        # Update number of clusters k\n",
    "        new_current_k = _ClustInstance.nclusters\n",
    "        update_k!(_SeriesInstance, new_current_k)\n",
    "        k = new_current_k\n",
    "\n",
    "        # Store series_clust and k_cent\n",
    "        _ClustUpdate = merge(+,_ClustUpdate,Dict(\"$k\" => copy(_ClustInstance)))\n",
    "        _SeriesUpdate = merge(+,_SeriesUpdate,Dict(\"$k\" => copy(_SeriesInstance)))\n",
    "\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: ArgumentError: @threads requires a `for` loop expression\nin expression starting at In[115]:36",
     "output_type": "error",
     "traceback": [
      "LoadError: ArgumentError: @threads requires a `for` loop expression\nin expression starting at In[115]:36",
      "",
      "Stacktrace:",
      " [1] var\"@threads\"(__source__::LineNumberNode, __module__::Module, args::Vararg{Any})",
      "   @ Base.Threads ./threadingconstructs.jl:146",
      " [2] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "function test_parallel(series::VecOrMat{Float64},\n",
    "    block_size::Int,\n",
    "    stopping_k::Int,\n",
    "    current_k::Int,\n",
    "    dm::Symbol,\n",
    "    rep_value::Symbol,\n",
    "    lseries::Int,\n",
    "    nseries::Int,\n",
    "    series_dc::VecOrMat{Float64},\n",
    "    ord_dc::VecOrMat{Int},\n",
    "    k_cent::VecOrMat{Float64},\n",
    "    weights::Vector{Int},\n",
    "    series_clust::Vector{Int},\n",
    "    nclusters::Int,\n",
    "    search_range::UnitRange,\n",
    "    dc_mode::Bool,\n",
    "    _SeriesInstance::SeriesInstance,\n",
    "    _ClustInstance::ClustInstance,\n",
    "    _DistUpdate::Dict{Vector{Bool},DistUpdate},\n",
    "    _SeriesUpdate::Dict{String,SeriesInstance},\n",
    "    _ClustUpdate::Dict{String,ClustInstance})\n",
    "\n",
    "    # @info \"Clustering the next step\"\n",
    "    k = lseries\n",
    "    @time while k >= stopping_k + block_size - 1\n",
    "        \n",
    "        # Vector with distances (to be updated as it goes)\n",
    "        dist = Vector{Float64}(undef,length(search_range))\n",
    "\n",
    "        # Sets\n",
    "        N = 1:nseries\n",
    "        K = copy(search_range)\n",
    "\n",
    "        # Compute the distance for each aggregation (i.e., changing the merging_clust)\n",
    "        # TODO: implement parallelisation such as '@async Threads.@threads @inbounds for k in K'\n",
    "        Threads.@threads for k_search in K\n",
    "            # Merging to be tested (neighbouring hypothesis)\n",
    "            # TODO: implement non-neighbouring hypothesis\n",
    "            merging_clust = k_search:k_search+block_size-1\n",
    "            # Create a temporary marker to merge the clusters tested\n",
    "            marker_temp = [sc in merging_clust for sc in series_clust]\n",
    "\n",
    "            # Separation needed for duration curves analysis\n",
    "            if dc_mode\n",
    "                # Create a temp marker for the elements in between clustered [min,max] order\n",
    "                marker_temp_dc = minimum(ord_dc[marker_temp,:]):maximum(ord_dc[marker_temp,:])\n",
    "                # Using duration curves chunks (in between the min and max values of marker_temp)\n",
    "                series_comp = sort(series, dims=1,rev=true)[marker_temp_dc,:]\n",
    "                # Forming the centroids\n",
    "                k_cent_comp = copy(series)\n",
    "                (k_cent_comp[marker_temp,:],) = aggreg1D(series[marker_temp,:], rep_value)\n",
    "                # Ordering chunk with clustering instance in a decrescent order\n",
    "                k_cent_comp = sort(k_cent_comp, dims=1, rev=true)[marker_temp_dc,:]\n",
    "            else\n",
    "                # Part of series compared\n",
    "                series_comp = series[marker_temp,:]\n",
    "                # Centroids of the temporarily formed cluster (TODO: implement another method for aggreg1D receiving the clusters with respective weights)\n",
    "                (k_cent_comp,) = aggreg1D(series_comp, rep_value)\n",
    "            end\n",
    "            \n",
    "            # Distance computation\n",
    "            dist[k_search] = compute_dist(N, dm, series_comp, k_cent_comp)\n",
    "        end\n",
    "\n",
    "        # Find whenever the min_dist occurs first (i.e., using findmin()[2])\n",
    "        ## TODO: implement the multiple merges (e.g., using findall())\n",
    "        min_dist = findmin(dist)[2] |> Int        \n",
    "        merging_clust = min_dist:min_dist+block_size-1\n",
    "\n",
    "        # Create a flag to the positions in the series that will be aggregated\n",
    "        marker = update_marker(_SeriesInstance, _ClustInstance, min_dist)    \n",
    "\n",
    "        # Update _DistUpdate dictionary with the minimal distance found and the new marker\n",
    "        _DistUpdate = merge(+, _DistUpdate, Dict(marker => DistUpdate(min_dist,merging_clust)))\n",
    "\n",
    "        # Update clusters and series_clust\n",
    "        update_clust!(_ClustInstance, _SeriesInstance, min_dist)\n",
    "\n",
    "        # Update clustering values\n",
    "        series_clust = _ClustInstance.series_clust\n",
    "        weights = _ClustInstance.weights\n",
    "\n",
    "        nclusters = _ClustInstance.nclusters\n",
    "        k_cent = _ClustInstance.k_cent\n",
    "        search_range =_ClustInstance.search_range\n",
    "        \n",
    "        # Update number of clusters k\n",
    "        new_current_k = _ClustInstance.nclusters\n",
    "        update_k!(_SeriesInstance, new_current_k)\n",
    "        k = new_current_k\n",
    "\n",
    "        # Store series_clust and k_cent\n",
    "        _ClustUpdate = merge(+,_ClustUpdate,Dict(\"$k\" => copy(_ClustInstance)))\n",
    "        _SeriesUpdate = merge(+,_SeriesUpdate,Dict(\"$k\" => copy(_SeriesInstance)))\n",
    "\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "execute_inst (generic function with 1 method)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function execute_inst(lseries::Int,nseries::Int,dc_mode::Bool; parallel=false)\n",
    "    \n",
    "    # Declare series\n",
    "    series = rand(lseries,nseries);\n",
    "    \n",
    "    # Forming SeriesInstance\n",
    "    block_size = 2\n",
    "    stopping_k = 1\n",
    "    current_k = lseries\n",
    "    rep_value = :mean\n",
    "    series_dc = sort(series, dims=1, rev=true)\n",
    "    ord_dc = reduce(hcat,sortperm.(collect(eachslice(series,dims=2)),rev=true))\n",
    "    \n",
    "    # Forming ClustInstance\n",
    "    k_cent = copy(series)\n",
    "    weights = ones(lseries) |> Vector{Int64}\n",
    "    series_clust = collect(1:lseries) |> Vector{Int64}\n",
    "    nclusters = lseries\n",
    "    search_range = 1:size(series,1)-block_size+1\n",
    "    dm = :ward\n",
    "\n",
    "    # Declaring instances\n",
    "    _SeriesInstance = load_series_instance(series,block_size,current_k,stopping_k,dm,rep_value,lseries,nseries,series_dc,ord_dc);\n",
    "    _ClustInstance = load_clust_instance(k_cent,series_clust,weights,search_range,dc_mode)\n",
    "\n",
    "    # Dictionary to keep the min distances and respective markers/min_dist found in each iteration\n",
    "    _DistUpdate = Dict{Vector{Bool}, DistUpdate}()\n",
    "\n",
    "    # Dictionaries to store series_clust and k_cent\n",
    "    _SeriesUpdate = Dict{String,SeriesInstance}()\n",
    "    _ClustUpdate = Dict{String,ClustInstance}();\n",
    "\n",
    "    if parallel\n",
    "        test_parallel(series,block_size,\n",
    "            stopping_k,\n",
    "            current_k,\n",
    "            dm,\n",
    "            rep_value,\n",
    "            lseries,\n",
    "            nseries,\n",
    "            series_dc,\n",
    "            ord_dc,\n",
    "            k_cent,\n",
    "            weights,\n",
    "            series_clust,\n",
    "            nclusters,\n",
    "            search_range,\n",
    "            dc_mode,\n",
    "            _SeriesInstance,\n",
    "            _ClustInstance,\n",
    "            _DistUpdate,\n",
    "            _SeriesUpdate,\n",
    "            _ClustUpdate)\n",
    "    else\n",
    "        test_serial(series,block_size,\n",
    "            stopping_k,\n",
    "            current_k,\n",
    "            dm,\n",
    "            rep_value,\n",
    "            lseries,\n",
    "            nseries,\n",
    "            series_dc,\n",
    "            ord_dc,\n",
    "            k_cent,\n",
    "            weights,\n",
    "            series_clust,\n",
    "            nclusters,\n",
    "            search_range,\n",
    "            dc_mode,\n",
    "            _SeriesInstance,\n",
    "            _ClustInstance,\n",
    "            _DistUpdate,\n",
    "            _SeriesUpdate,\n",
    "            _ClustUpdate)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: 100 lines random series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.621945 seconds (876.02 k allocations: 177.997 MiB, 5.78% gc time, 70.29% compilation time)\n"
     ]
    }
   ],
   "source": [
    "execute_inst(100,4,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.040128 seconds (214.85 k allocations: 22.252 MiB)\n"
     ]
    }
   ],
   "source": [
    "execute_inst(100,4,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: 200 lines random series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.485150 seconds (1.32 M allocations: 1.085 GiB, 5.22% gc time)\n"
     ]
    }
   ],
   "source": [
    "execute_inst(200,4,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.196800 seconds (839.81 k allocations: 111.477 MiB, 7.11% gc time)\n"
     ]
    }
   ],
   "source": [
    "execute_inst(200,4,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: 500 lines random series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_inst(500,4,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_inst(500,4,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: parallelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.588317 seconds (3.00 M allocations: 3.734 GiB, 8.40% gc time)\n"
     ]
    }
   ],
   "source": [
    "execute_inst(300,4,true,parallel=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "TaskFailedException\n\n\u001b[91m    nested task error: \u001b[39mArgumentError: reducing over an empty collection is not allowed\n    Stacktrace:\n      [1] \u001b[0m\u001b[1m_empty_reduce_error\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:301\u001b[24m\u001b[39m\n      [2] \u001b[0m\u001b[1mreduce_empty\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mop\u001b[39m::\u001b[0mFunction, \u001b[90m#unused#\u001b[39m::\u001b[0mType\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:311\u001b[24m\u001b[39m\n      [3] \u001b[0m\u001b[1mmapreduce_empty\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90m#unused#\u001b[39m::\u001b[0mtypeof(identity), \u001b[90mop\u001b[39m::\u001b[0mFunction, \u001b[90mT\u001b[39m::\u001b[0mType\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:345\u001b[24m\u001b[39m\n      [4] \u001b[0m\u001b[1mreduce_empty\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mop\u001b[39m::\u001b[0mBase.MappingRF\u001b[90m{typeof(identity), typeof(min)}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mType\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:331\u001b[24m\u001b[39m\n      [5] \u001b[0m\u001b[1mreduce_empty_iter\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:357\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n      [6] \u001b[0m\u001b[1mmapreduce_empty_iter\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mFunction, \u001b[90mop\u001b[39m::\u001b[0mFunction, \u001b[90mitr\u001b[39m::\u001b[0mMatrix\u001b[90m{Int64}\u001b[39m, \u001b[90mItrEltype\u001b[39m::\u001b[0mBase.HasEltype\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:353\u001b[24m\u001b[39m\n      [7] \u001b[0m\u001b[1m_mapreduce\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(identity), \u001b[90mop\u001b[39m::\u001b[0mtypeof(min), \u001b[90m#unused#\u001b[39m::\u001b[0mIndexLinear, \u001b[90mA\u001b[39m::\u001b[0mMatrix\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:402\u001b[24m\u001b[39m\n      [8] \u001b[0m\u001b[1m_mapreduce_dim\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:330\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n      [9] \u001b[0m\u001b[1m#mapreduce#725\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:322\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [10] \u001b[0m\u001b[1mmapreduce\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:322\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [11] \u001b[0m\u001b[1m#_minimum#747\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [12] \u001b[0m\u001b[1m_minimum\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [13] \u001b[0m\u001b[1m#_minimum#746\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:893\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [14] \u001b[0m\u001b[1m_minimum\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:893\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [15] \u001b[0m\u001b[1m#minimum#744\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [16] \u001b[0m\u001b[1mminimum\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ma\u001b[39m::\u001b[0mMatrix\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:889\u001b[24m\u001b[39m\n     [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[99]:46\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [18] \u001b[0m\u001b[1m(::var\"#564#threadsfor_fun#217\"{Matrix{Float64}, Int64, Symbol, Symbol, Matrix{Int64}, Bool, UnitRange{Int64}, Vector{Float64}, UnitRange{Int64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90monethread\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mthreadingconstructs.jl:85\u001b[24m\u001b[39m\n     [19] \u001b[0m\u001b[1m(::var\"#564#threadsfor_fun#217\"{Matrix{Float64}, Int64, Symbol, Symbol, Matrix{Int64}, Bool, UnitRange{Int64}, Vector{Float64}, UnitRange{Int64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mthreadingconstructs.jl:52\u001b[24m\u001b[39m",
     "output_type": "error",
     "traceback": [
      "TaskFailedException\n\n\u001b[91m    nested task error: \u001b[39mArgumentError: reducing over an empty collection is not allowed\n    Stacktrace:\n      [1] \u001b[0m\u001b[1m_empty_reduce_error\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:301\u001b[24m\u001b[39m\n      [2] \u001b[0m\u001b[1mreduce_empty\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mop\u001b[39m::\u001b[0mFunction, \u001b[90m#unused#\u001b[39m::\u001b[0mType\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:311\u001b[24m\u001b[39m\n      [3] \u001b[0m\u001b[1mmapreduce_empty\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90m#unused#\u001b[39m::\u001b[0mtypeof(identity), \u001b[90mop\u001b[39m::\u001b[0mFunction, \u001b[90mT\u001b[39m::\u001b[0mType\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:345\u001b[24m\u001b[39m\n      [4] \u001b[0m\u001b[1mreduce_empty\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mop\u001b[39m::\u001b[0mBase.MappingRF\u001b[90m{typeof(identity), typeof(min)}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mType\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:331\u001b[24m\u001b[39m\n      [5] \u001b[0m\u001b[1mreduce_empty_iter\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:357\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n      [6] \u001b[0m\u001b[1mmapreduce_empty_iter\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mFunction, \u001b[90mop\u001b[39m::\u001b[0mFunction, \u001b[90mitr\u001b[39m::\u001b[0mMatrix\u001b[90m{Int64}\u001b[39m, \u001b[90mItrEltype\u001b[39m::\u001b[0mBase.HasEltype\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:353\u001b[24m\u001b[39m\n      [7] \u001b[0m\u001b[1m_mapreduce\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(identity), \u001b[90mop\u001b[39m::\u001b[0mtypeof(min), \u001b[90m#unused#\u001b[39m::\u001b[0mIndexLinear, \u001b[90mA\u001b[39m::\u001b[0mMatrix\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreduce.jl:402\u001b[24m\u001b[39m\n      [8] \u001b[0m\u001b[1m_mapreduce_dim\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:330\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n      [9] \u001b[0m\u001b[1m#mapreduce#725\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:322\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [10] \u001b[0m\u001b[1mmapreduce\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:322\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [11] \u001b[0m\u001b[1m#_minimum#747\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [12] \u001b[0m\u001b[1m_minimum\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:894\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [13] \u001b[0m\u001b[1m#_minimum#746\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:893\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [14] \u001b[0m\u001b[1m_minimum\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:893\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [15] \u001b[0m\u001b[1m#minimum#744\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:889\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [16] \u001b[0m\u001b[1mminimum\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90ma\u001b[39m::\u001b[0mMatrix\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mreducedim.jl:889\u001b[24m\u001b[39m\n     [17] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[99]:46\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [18] \u001b[0m\u001b[1m(::var\"#564#threadsfor_fun#217\"{Matrix{Float64}, Int64, Symbol, Symbol, Matrix{Int64}, Bool, UnitRange{Int64}, Vector{Float64}, UnitRange{Int64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90monethread\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mthreadingconstructs.jl:85\u001b[24m\u001b[39m\n     [19] \u001b[0m\u001b[1m(::var\"#564#threadsfor_fun#217\"{Matrix{Float64}, Int64, Symbol, Symbol, Matrix{Int64}, Bool, UnitRange{Int64}, Vector{Float64}, UnitRange{Int64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m    @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mthreadingconstructs.jl:52\u001b[24m\u001b[39m",
      "",
      "Stacktrace:",
      "  [1] wait",
      "    @ ./task.jl:334 [inlined]",
      "  [2] threading_run(func::Function)",
      "    @ Base.Threads ./threadingconstructs.jl:38",
      "  [3] macro expansion",
      "    @ ./threadingconstructs.jl:97 [inlined]",
      "  [4] macro expansion",
      "    @ ./In[99]:36 [inlined]",
      "  [5] macro expansion",
      "    @ ./timing.jl:220 [inlined]",
      "  [6] test_parallel(series::Matrix{Float64}, block_size::Int64, stopping_k::Int64, current_k::Int64, dm::Symbol, rep_value::Symbol, lseries::Int64, nseries::Int64, series_dc::Matrix{Float64}, ord_dc::Matrix{Int64}, k_cent::Matrix{Float64}, weights::Vector{Int64}, series_clust::Vector{Int64}, nclusters::Int64, search_range::UnitRange{Int64}, dc_mode::Bool, _SeriesInstance::SeriesInstance{Float64, Int64}, _ClustInstance::ClustInstance{Float64, Int64}, _DistUpdate::Dict{Vector{Bool}, DistUpdate}, _SeriesUpdate::Dict{String, SeriesInstance}, _ClustUpdate::Dict{String, ClustInstance})",
      "    @ Main ./In[99]:25",
      "  [7] execute_inst(lseries::Int64, nseries::Int64, dc_mode::Bool; parallel::Bool)",
      "    @ Main ./In[116]:34",
      "  [8] top-level scope",
      "    @ In[124]:1",
      "  [9] eval",
      "    @ ./boot.jl:373 [inlined]",
      " [10] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "execute_inst(300,4,true,parallel=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
